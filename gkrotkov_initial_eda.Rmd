---
title: "Health Exams in Vietnam"
author: "Gabriel Krotkov"
date: "2023-12-05"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
theme_set(theme_bw())
library(gridExtra)
load("data.rda")
```

\newpage

# Data

The data are survey responses from the cities of Hanoi and Hung Yen, Vietnam focused on "secondary schools, hospitals, companies, government agencies and randomly selected households"

For two of the key research questions in this report, the variable we will choose as the response variable is `RecPerExam`, a measure of how long it has been since the respondent last had a checkup *without* a catalyzing health event motivating them to go to the doctor. For this variable, 516 of the 2068 respondents had a value of `unknown`. There are many possible explanations for not knowing how long it has been since your most recent personal checkup, some of which cut against each other when it comes to interpreting the analysis. For example, if a respondent reported "unknown" because it has been so long they cannot remember, that has a very different impact on what inferences we should draw about that respondent than if they reported "unknown" because they were unsure if it was 11 months ago or 12 months ago. Since we don't have any additional information about the reasoning behind the `unknown` status, we will remove all respondents who reported `unkown` from the dataset for the remainder of the analysis.

## Interpreting 

# EDA

## Information Ratings

```{r}
suff_plot <- ggplot(data, aes(x = SuffInfo)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Sufficiency Ratings", 
         x = "Information Sufficiency")

attract_plot <- ggplot(data, aes(x = AttractInfo)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Attractiveness Ratings", 
         x = "Information Attractiveness")

impress_plot <- ggplot(data, aes(x = ImpressInfo)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Impressiveness Ratings", 
         x = "Information Impresiveness")

popular_plot <- ggplot(data, aes(x = PopularInfo)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Popularity Ratings", 
         x = "Information Popularity")

avg_plot <- ggplot(data, aes(x = (SuffInfo + AttractInfo + 
                                      ImpressInfo + PopularInfo) / 4)) + 
    geom_histogram(bins = 12, fill = "purple", color = "black") + 
    labs(title = "Average plot", 
         x = "Avg Info Rating")

grid.arrange(suff_plot, attract_plot, impress_plot, popular_plot, 
             nrow = 2)

avg_plot

tukey_summaries <- rbind(quantile(data$SuffInfo), quantile(data$AttractInfo), 
                         quantile(data$ImpressInfo), quantile(data$PopularInfo))
rownames(tukey_summaries) <- c("Sufficiency", "Attractiveness", 
                               "Impressiveness", "Popularity")

knitr::kable(tukey_summaries)
```

People tend to rate the Sufficiency, Attractiveness, Impressiveness, and Popularity of information received from checkups at a 3/5 on average, with a similar distribution for each variable. For Attractiveness in particular there appears to be a slight asymmetry (with 2/5 getting nearly as high a rating as 3/5), but in general the four plots all agree on the distribution of the response. We can also see from the table of quantiles that the 5-number summaries for all the variables are identical. Taken together, I am comfortable using Impressiveness as a proxy for all the response variables, since its distribution seems to be the closest to the average of all the other distributions. 

We will also explore some metrics of checkup quality to get an indicator for how quality current checkups are.

```{r}
reliability_plot <- ggplot(data, aes(x = Reliability)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Reliability Rating", 
         x = "Reliability")

assurance_plot <- ggplot(data, aes(x = Assurance)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Assurance Rating", 
         x = "Assurance")

empathy_plot <- ggplot(data, aes(x = Empathy)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Empathy Rating", 
         x = "Empathy")

tangibles_plot <- ggplot(data, aes(x = Tangibles)) + 
    geom_bar(fill = "purple", color = "black") + 
    labs(title = "Tangibles Rating", 
         x = "Tangibles")

grid.arrange(reliability_plot, assurance_plot, empathy_plot, tangibles_plot, 
             nrow = 2)
```

For key metrics of care quality, we can see that on average patients rate their care reasonably highly. There is clear leftward skew in each of the plots, and ratings of 1 and 2 are relatively rare. It seems like the performance metric with the most opportunity for the Ministry to improve is `empathy`, since while a very high number of patients gave a score of 5/5, the combined count for scores 1/5 and 2/5 is the highest of the variables we consider here.

## Factors Influencing Checkup Consistency

Among reliability, empathy, tangibles, and assurance, we are interested in finding the variables that most impact checkup consistency. To investigate this, we can plot each of the variables of interest across the different levels of checkup recency.

```{r}
reliability_plot <- ggplot(data, aes(x = RecPerExam, y = Reliability)) + 
    geom_violin(fill = "darkorange", alpha = 0.6) + 
    geom_boxplot(fill = "purple", alpha = 0.6) + 
    labs(title = "Reliability across exam consistencies")

empathy_plot <- ggplot(data, aes(x = RecPerExam, y = Empathy)) + 
    geom_violin(fill = "darkorange", alpha = 0.6) + 
    geom_boxplot(fill = "purple", alpha = 0.6) + 
    labs(title = "Empathy across exam consistencies")

tangibles_plot <- ggplot(data, aes(x = RecPerExam, y = Tangibles)) + 
    geom_violin(fill = "darkorange", alpha = 0.6) + 
    geom_boxplot(fill = "purple", alpha = 0.6) + 
    labs(title = "Tangibles across exam consistencies")

assurance_plot <- ggplot(data, aes(x = RecPerExam, y = Assurance)) + 
    geom_violin(fill = "darkorange", alpha = 0.6) + 
    geom_boxplot(fill = "purple", alpha = 0.6) + 
    labs(title = "Assurance across exam consistencies")

grid.arrange(reliability_plot, assurance_plot, empathy_plot, tangibles_plot, 
             nrow = 2)
```

We can see from these plots that it appears that the biggest and most consistent difference in distribution appears to be across the `Empathy` variable - the mean appears to clearly take a different value among lower empathy values, compared to less clear effects along the other variables.

## Impact of Health Issues

```{r}
mosaicplot(table(data$RecPerExam, 
                 data$StabHthStt))
```
From the mosaic plot, it appears that health issues among the respondants and their families are not correlated to the response variable.

# Instructions for statistical analyses

Create linear models testing the hypotheses created in the above two parts, including interaction terms for testing the interaction effects. 
