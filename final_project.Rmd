---
title: "Health Exams in Vietnam"
author: "Gabriel Krotkov, Zachary Strennen"
date: "2023-12-13"
output: pdf_document
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
theme_set(theme_bw())
library(gridExtra)
library(leaps)
library(reshape2)
load("data.rda")
```

# Executive Summary

\newpage

# Introduction

The Ministry of Health ("Ministry" or "the Ministry") seeks to increase public attendance at regular checkups both to improve public health and save money with preventative medicine. To address this problem, Vietnamese public health researchers conducted a survey to gather information about public attitudes around regular checkups. We will use this data to answer critical questions by the Ministry aimed at increasing the number of people getting annual health exams. 

In particular, we will answer the following questions to guide Ministry policy around regular checkups:

1. Overall, how do people rate the attractiveness, impressiveness, sufficiency, and popularity of information they receive in checkups?
2. How do people rate attributes, such as assurance, reliability, and empathy, that tell us how well doctors and nurses are doing?
3. What make a person less likely to get check-up every twelve months and of these factors which can be used to design advertising for check-ups?
4. Do none of these factors matter unless a person has health issues or knows someone in their family with health issues?

# Data

The data were collected by public health researchers in Vietnam in order to determine what obstacles were preventing widespread us of regular check-ups. The researchers conducted interviews in Hanoi and Hung Yen Vietnam and primarily traveled to secondary schools, hospitals, companies, government agencies and randomly selected households in Hanoi. The interviews were in person and lasted about 10-15 minutes. Out of the 2,479 people approached, there were 2,068 valid responses added to the data.

For two of the key research questions in this report, the variable we will choose as the response variable is `RecPerExam`, a measure of how long it has been since the respondent last had a checkup *without* a catalyzing health event motivating them to go to the doctor. For this variable, 516 of the 2068 respondents had a value of `unknown`. There are many possible explanations for not knowing how long it has been since your most recent personal checkup, some of which cut against each other when it comes to interpreting the analysis. For example, if a respondent reported "unknown" because it has been so long they cannot remember, that has a very different impact on what inferences we should draw about that respondent than if they reported "unknown" because they were unsure if it was 11 months ago or 12 months ago. Since we don't have any additional information about the reasoning behind the `unknown` status, we will remove all respondents who reported `unkown` from the dataset for the remainder of the analysis.

As part of the data cleaning, we removed all respondents whose reason for getting a checkup was because their employer or insurance requested that they do. These semi-compulsory exams are not useful information for getting at the Ministry's fundamental question - how do we drive more voluntary checkups? Removing such entries allows us to narrow our focus to those who are not immediately pressured to get a check-up.

# Exploratory Data Analysis

## Information Ratings

To answer the Ministry's first research question, we can investigate respondents' ratings of key information features visually.

```{r, fig.height = 4, fig.align='center'}
data$info_avg <- (data$SuffInfo + data$AttractInfo + 
    data$ImpressInfo + data$PopularInfo) / 4
cidx <- which(colnames(data) %in% c("SuffInfo", "AttractInfo", 
                                    "ImpressInfo", "PopularInfo", "info_avg"))

info <- melt(data[, cidx])
info$variable <- factor(info$variable, 
                        levels = c("SuffInfo", "AttractInfo", "ImpressInfo", 
                                   "PopularInfo", "info_avg"),
                        labels = c("Sufficiency", "Attractiveness", 
                                   "Impressiveness", "Popularity", 
                                   "Avg Rating"))
colnames(info) <- c("Type", "value")

ggplot(info, aes(x = value, color = Type)) + 
    geom_density(alpha = 0.3, bw = 0.35) + 
    labs(title = "Information Types Have Very Similar Distributions", 
         x = "Rating (1-5 scale)", y = "Density", 
         caption = "Figure 1: Information Type")

rm(info)
```

People tend to rate the Sufficiency, Attractiveness, Impressiveness, and Popularity of information received from checkups at a 3/5 on average, with a similar distribution for each variable. Sufficiency in particular appears to slightly deviate from the rest of the distributions, with a slightly lower density at 2/5 and a slightly higher density at 3/5, but overall the ratings clearly vary together. This is supported by the closely matching means and standard deviations of the four variables, shown in the table below.

```{r}
summ_stat <- data.frame(mean = c(mean(data$SuffInfo), 
                                 mean(data$AttractInfo), 
                                 mean(data$ImpressInfo), 
                                 mean(data$PopularInfo)), 
                        stdev = c(sd(data$SuffInfo), sd(data$AttractInfo), 
                                  sd(data$ImpressInfo), sd(data$PopularInfo)))

rownames(summ_stat) <- c("Sufficiency", "Attractiveness", 
                         "Impressiveness", "Popularity")

knitr::kable(summ_stat, 
             caption = "Figure 2: Information Summary Statistics")
```

We can also get a sense of the extent to which the variables tend to vary together by taking the standard deviation of each respondent's four ratings and plotting those standard deviations.

```{r, fig.height = 3, fig.width = 4, fig.align = 'center'}
cidx <- which(colnames(data) %in% c("SuffInfo", "AttractInfo", 
                                    "ImpressInfo", "PopularInfo"))

ggplot(data.frame(sd_scores = apply(data[, cidx], MARGIN = 1, sd)), 
       aes(x = sd_scores)) + 
    geom_histogram(bins = 8, fill = "purple", color = "black") + 
    labs(title = "Respondent Standard Deviation",
         subtitle = "Across Info Metrics",
         x = "Respondent Standard Deviation", y = "Count", 
         caption = "Figure 3: Spread between ratings")

rm(summ_stat)
```

This indicates in general that the average respondent is generally either pleased or not pleased with the information given to them in a checkup, and doesn't tend to distinguish between the Sufficiency, Attractiveness, Impressiveness or Popularity of the information. The average standard deviation of the respondent's scores across each information metric is a very right skewed and left centered metric, indicating that respondents' scores do not vary much across the different metrics. Taken together with the close matching of the average metric plot and the Information Impressiveness plot, it is a safe simplification to use Information Impressiveness as a proxy for the respondent's overall satisfaction with information provided at a checkup.

## Checkup Quality

We can also explore some metrics of checkup quality to get an indicator for how quality current checkups are, as per the Ministry's questions.

```{r}
cidx <- which(colnames(data) %in% c("Tangibles", "Reliability", "Timeliness", 
                                    "Assurance", "Empathy"))
quality <- melt(data[, cidx])
colnames(quality) <- c("Rating", "value")

knitr::kable(data.frame(mean = colMeans(data[, cidx]), 
                        sd = apply(data[, cidx], 2, sd)), 
             caption = "Figure 4: Quality Summary Statistics")

```

```{r}
ggplot(quality, aes(x = value, fill = Rating)) + 
    geom_density(alpha = 0.6, bw = 0.35) + 
    facet_wrap(~Rating) + 
    labs(title = "Quality Ratings Distribution", 
         x = "Rating (1-5)", y = "Density", 
         caption = "Figure 5: Quality Ratings")
```

```{r}
rm(quality)
```

## What Drives Voluntary Checkups?

```{r, echo=FALSE}
# Does the respondent believe check-ups are a waste of money?
barplot1 <-
    data %>% ggplot(aes(x = Wstmon, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Are check-ups a waste\nof money?",
         fill="Months since\nlast check-up")

# Is the respondent afraid of check-ups because they're afraid of discovering a disease?
barplot2 <-
    data %>% ggplot(aes(x = DiscDisease, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Are you afriad of discovering\na new disease?",
         fill="Months since\nlast check-up")

# Does the respondent have little faith in the quality of medical service?
barplot3 <-
    data %>% ggplot(aes(x = Lessbelqual, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Do you have little faith in\nthe quality of medical\nservice?",
         fill="Months since\nlast check-up")

# Does the respondent believe check-ups are not urgent or important?
barplot4 <-
    data %>% ggplot(aes(x = NotImp, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Do you believe check-ups are\nnot urgent or important?",
         fill="Months since\nlast check-up")

# Does the respondent believe health is a first priority?
barplot5 <-
    data %>% ggplot(aes(x = HthyPriority, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Do you believe health is a\nfirst priority?",
         fill="Months since\nlast check-up")

# Are check-ups subsidized by the respondent's employer or community?
barplot6 <-
    data %>% ggplot(aes(x = FlwHealth, y = after_stat(count), fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="",
         y="Frequency",
         title = "Does you constantly follow updates your health measures?",
         fill="Months since\nlast check-up")

grid.arrange(barplot1, barplot2, barplot3, barplot4, ncol=2,nrow=2)
grid.arrange(barplot5, barplot6, ncol=2,nrow=2)

rm(barplot1, barplot2, barplot3, barplot4, barplot5, barplot6)
```

# Methods

Idea: build two models, one model is the model-selected-by-BIC one that tells the health ministry which variables drive what they want. The second model then includes many more variables to control variance so that we can tell the ministry *how much* each covariate influences the result.

```{r, echo=FALSE}
# Convert yes/no variables to binary
data$StabHthStt <- ifelse(data$StabHthStt=="yes",1,0)
data$Wstmon <- ifelse(data$Wstmon=="yes",1,0)
data$DiscDisease <- ifelse(data$DiscDisease=="yes",1,0)
data$Lessbelqual <- ifelse(data$Lessbelqual=="yes",1,0)
data$NotImp <- ifelse(data$NotImp=="yes",1,0)
data$HthyPriority <- ifelse(data$HthyPriority=="yes",1,0)
data$FlwHealth <- ifelse(data$FlwHealth=="yes",1,0)
```

```{r,echo=FALSE}
# BIC selection
num_pred_variables <- 18
regfit.full <- regsubsets(RecPerExam ~
                            StabHthStt +
                            BMI +
                            Wstmon +
                            Wsttime +
                            DiscDisease +
                            Lessbelqual +
                            NotImp + 
                            HthyPriority +
                            ComSubsidy +
                            Habit + 
                            FlwHealth +
                            AttractInfo +
                            ImpressInfo +
                            SuffInfo +
                            PopularInfo +
                            Assurance +
                            Reliability + 
                            Empathy,
                          data = data,
                          nvmax = num_pred_variables,
                          method = "forward")

reg.summary <- summary(regfit.full)
var_num_bic <- which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
points(var_num_bic, reg.summary$bic[var_num_bic], col = "red", cex = 2, pch = 20)
coef(regfit.full, var_num_bic)
```

```{r}
# Final model with BIC
glm <- glm(as.numeric(RecPerExam) ~ Wsttime + NotImp + HthyPriority + ComSubsidy + Habit,data=data)
summary(glm)
par(mfrow=c(2,2))
plot(glm)
```

# Results

## Information Ratings

Overall, respondents rate the four types of information (attractiveness, impressiveness, sufficiency, and popularity) with approximately the same distribution (see Figure 1); unimodal, centered at around 3 and slightly right skewed, with slightly more respondents responding with 2/5 then 4/5 and slightly more respondents responding with 1/5 than 5/5. It appears that in general, referencing the tight spread of each individual respondent's rating seen in Figure 3, not only does each type of information have the same marginal distribution, but each individual respondent's ratings are tightly clustered. That is, most respondents gave ratings for the four different information types that are very similar to each other.

## Attribute Ratings

For key metrics of care quality, we can see from Figure 5 that on average patients rate their care reasonably highly. There is clear leftward skew from a high center in each of the plots, and ratings of 1 and 2 are relatively rare. It seems like the performance metrics with the most opportunity for the Ministry to improve are Timeliness and Empathy, since while a reasonable number of patients gave a score of 5/5 for these qualities, these two qualities have the highest density of 1/5 and 2/5 ratings, clearly higher than the other three qualities.

@TODO write our response to Q2

@TODO write out response to Q3

# Conclusions
