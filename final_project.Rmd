---
title: "Health Exams in Vietnam"
author: "Gabriel Krotkov, Zachary Strennen"
date: "2023-12-13"
output: pdf_document
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
theme_set(theme_bw())
library(gridExtra)
library(leaps)
library(reshape2)
load("data.rda")
fig_n <- 1

fig_cap <- function(label){
    cap <- paste0("Figure ", fig_n, ": ", label)
    fig_n <<- fig_n + 1
    return(cap)
}

diagnostics_glm <- function(glm_out, alpha = 0.05){
    require(MASS)
    p <- length(glm_out$coefficients) - 1  # -1 to account for the intercept
    n <- length(glm_out$fitted.values)
    par(mfrow = c(ceiling((6 + p) / 3), 3))
    # (1) Y-hat vs Y with 0, 1 line and loess fit
    plot(y = glm_out$fitted.values, x = glm_out$y, 
         main = "Y-hat vs Y", xlab = "Response", ylab = "Fitted Values")
    ord <- order(glm_out$y)
    lines(y = glm_out$fitted.values[ord], x = glm_out$y[ord])
    abline(0, 1, col = "red", lty = 2)
    # (2) Standardized deviance resids vs Y-hat w/x = {-2, 0, 2} and loess
    dev_resid <- resid(glm_out, type = "deviance")
    stan_dev_resid <- scale(dev_resid)
    plot(stan_dev_resid ~ glm_out$fitted.values, 
         main = "Std. Deviance Residuals vs Y-hat", 
         xlab = "Fitted Values", ylab = "Standardized Deviance Resid")
    ord <- order(glm_out$fitted.values)
    lines(y = stan_dev_resid[ord], x = glm_out$fitted.values[ord])
    abline(h = c(-2, 0, 2), lty = 2)
    # Studentized deviance residuals vs Y.hat with lines at -(alpha/2n) and 
    # +(alpha/2n) quantiles of the standard normal distribution
    plot(x = glm_out$fitted.values, y = dev_resid / sd(dev_resid), 
         main = "Studentized Deviance Residuals", 
         xlab = "Fitted Values", ylab = "Studentized Deviance Resid")
    abline(h = c(qnorm(alpha / (2 * n)), qnorm(1 - alpha / (2 * n))), 
           col = "red", lty = 2)
    # leverage values vs fitted, horizontal cut-offs
    plot(x = glm_out$fitted.values, y = hatvalues(glm_out), 
         main = "Leverage vs Fitted", 
         xlab = "Fitted Values", ylab = "Leverage")
    # Cook's distance plot
    plot(cooks.distance(glm_out), x = 1:n, 
         main = "Cook's Distance Plot", 
         xlab = "Obs #", ylab = "Cook's Distance")
    abline(h = abs(qf(0.5, p, n - p)), col = "orange", lty = 2)
    abline(h = 1, col = "red", lty = 2)

    # QQNorm plot of standardized deviance residuals
    qqnorm(stan_dev_resid)
    abline(0, 1)
    # Standardized deviance residuals against each covariate
    covariates <- names(glm_out$coefficients)[2:p]
    for (i in 1:p){
        plot(y = stan_dev_resid, x = glm_out$model[, covariates[i]], 
             main = paste("Covariate", i, sep = " "))
    }
}
```

# Executive Summary

\newpage

# Introduction

The Ministry of Health ("Ministry" or "the Ministry") seeks to increase public attendance at regular checkups both to improve public health and save money with preventative medicine. Specifically, they are seeking advertising recommendations to encourage regular check-ups to those who are shy to the notion. To address this problem, Vietnamese public health researchers conducted a survey to gather information about public attitudes around regular checkups. We will use this data to answer critical questions by the Ministry aimed at increasing the number of people getting annual health exams. 

In particular, we will answer the following questions to guide Ministry policy around regular checkups:

1. Overall, how do people rate the attractiveness, impressiveness, sufficiency, and popularity of information they receive in checkups?
2. How do people rate attributes, such as assurance, reliability, and empathy, that tell us how well doctors and nurses are doing?
3. What make a person less likely to get check-up every twelve months and of these factors which can be used to design advertising for check-ups?
4. Do none of these factors matter unless a person has health issues or knows someone in their family with health issues?

# Data

The data were collected by public health researchers in Vietnam in order to determine what obstacles were preventing widespread us of regular check-ups. The researchers conducted interviews in Hanoi and Hung Yen Vietnam and primarily traveled to secondary schools, hospitals, companies, government agencies and randomly selected households in Hanoi. The interviews were in person and lasted about 10-15 minutes. Out of the 2,479 people approached, there were 2,068 valid responses added to the data.

For two of the key research questions in this report, the variable we will choose as the response variable is `RecPerExam`, a measure of how long it has been since the respondent last had a checkup *without* a catalyzing health event motivating them to go to the doctor. For this variable, 516 of the 2068 respondents had a value of `unknown`. There are many possible explanations for not knowing how long it has been since your most recent personal checkup, some of which cut against each other when it comes to interpreting the analysis. For example, if a respondent reported "unknown" because it has been so long they cannot remember, that has a very different impact on what inferences we should draw about that respondent than if they reported "unknown" because they were unsure if it was 11 months ago or 12 months ago. Since we don't have any additional information about the reasoning behind the `unknown` status, we will remove all respondents who reported `unkown` from the dataset for the remainder of the analysis.

As part of the data cleaning, we removed all respondents whose reason for getting a checkup was because their employer or insurance requested that they do. These semi-compulsory exams are not useful information for getting at the Ministry's fundamental question - how do we drive more voluntary checkups? Removing such entries allows us to narrow our focus to those who are not immediately pressured to get a check-up.

# Exploratory Data Analysis

## Information Ratings

To answer the Ministry's first research question, we can investigate respondents' ratings of key information features visually.

```{r, fig.height = 4, fig.align='center'}
data$info_avg <- (data$SuffInfo + data$AttractInfo + 
    data$ImpressInfo + data$PopularInfo) / 4
cidx <- which(colnames(data) %in% c("SuffInfo", "AttractInfo", 
                                    "ImpressInfo", "PopularInfo", "info_avg"))

info <- melt(data[, cidx])
info$variable <- factor(info$variable, 
                        levels = c("SuffInfo", "AttractInfo", "ImpressInfo", 
                                   "PopularInfo", "info_avg"),
                        labels = c("Sufficiency", "Attractiveness", 
                                   "Impressiveness", "Popularity", 
                                   "Avg Rating"))
colnames(info) <- c("Type", "value")

ggplot(info, aes(x = value, color = Type)) + 
    geom_density(alpha = 0.3, bw = 0.35) + 
    labs(title = "Information Types Have Very Similar Distributions", 
         x = "Rating (1-5 scale)", y = "Density", 
         caption = fig_cap("Information Type"))

rm(info)
```

People tend to rate the Sufficiency, Attractiveness, Impressiveness, and Popularity of information received from checkups at a 3/5 on average, with a similar distribution for each variable. Sufficiency in particular appears to slightly deviate from the rest of the distributions, with a slightly lower density at 2/5 and a slightly higher density at 3/5, but overall the ratings clearly vary together. This is supported by the closely matching means and standard deviations of the four variables, shown in the table below.

```{r}
summ_stat <- data.frame(mean = c(mean(data$SuffInfo), 
                                 mean(data$AttractInfo), 
                                 mean(data$ImpressInfo), 
                                 mean(data$PopularInfo)), 
                        stdev = c(sd(data$SuffInfo), sd(data$AttractInfo), 
                                  sd(data$ImpressInfo), sd(data$PopularInfo)))

rownames(summ_stat) <- c("Sufficiency", "Attractiveness", 
                         "Impressiveness", "Popularity")

knitr::kable(summ_stat, caption = "Information Summary Statistics")
```

We can also get a sense of the extent to which the variables tend to vary together by taking the standard deviation of each respondent's four ratings and plotting those standard deviations.

```{r, fig.height = 3, fig.width = 4, fig.align = 'center'}
cidx <- which(colnames(data) %in% c("SuffInfo", "AttractInfo", 
                                    "ImpressInfo", "PopularInfo"))

ggplot(data.frame(sd_scores = apply(data[, cidx], MARGIN = 1, sd)), 
       aes(x = sd_scores)) + 
    geom_histogram(bins = 8, fill = "purple", color = "black") + 
    labs(title = "Respondent Standard Deviation",
         subtitle = "Across Info Metrics",
         x = "Respondent Standard Deviation", y = "Count", 
         caption = fig_cap("Spread Between Ratings"))

rm(summ_stat)
```

This indicates in general that the average respondent is generally either pleased or not pleased with the information given to them in a checkup, and doesn't tend to distinguish between the Sufficiency, Attractiveness, Impressiveness or Popularity of the information. The average standard deviation of the respondent's scores across each information metric is a very right skewed and left centered metric, indicating that respondents' scores do not vary much across the different metrics. Taken together with the close matching of the average metric plot and the Information Impressiveness plot, it is a safe simplification to use Information Impressiveness as a proxy for the respondent's overall satisfaction with information provided at a checkup.

## Checkup Quality

We can also explore some metrics of checkup quality to get an indicator for how quality current checkups are, as per the Ministry's questions.

```{r}
cidx <- which(colnames(data) %in% c("Tangibles", "Reliability", "Timeliness", 
                                    "Assurance", "Empathy"))
quality <- melt(data[, cidx])
colnames(quality) <- c("Rating", "value")

knitr::kable(data.frame(mean = colMeans(data[, cidx]), 
                        sd = apply(data[, cidx], 2, sd)), 
             caption = "Quality Summary Statistics")
```

```{r}
ggplot(quality, aes(x = value, fill = Rating)) + 
    geom_density(alpha = 0.6, bw = 0.35) + 
    facet_wrap(~Rating) + 
    labs(title = "Quality Ratings Distribution", 
         x = "Rating (1-5)", y = "Density", 
         caption = fig_cap("Quality Ratings"))
```

```{r}
rm(quality)
```

## What Drives Voluntary Checkups?

Each response includes the several yes or no questions asking what each person feels about check-ups. For example, "Does the respondent believe check-ups are a waste of time?" Figures 9 through 16 show the distributions of the answers to these questions as they relate to `RecPerExam`. We are looking to see that the distribution of each answer differs between yes and no. In figure 10, we can clearly see that being afraid of discovering a new disease causes someone to wait more than twelve months to get a check-up. This is evident from the size difference between each bar representing those who got a check-up in less than twelve months. While some yes or no answers' distributions look more identical then others, we will still proceed with using most of these variables during model selction as we should not ignore nuanced changes via visualizations alone.

```{r, fig.height = 8, echo=FALSE}
# Does the respondent believe check-ups are a waste of time?
barplot1 <-
    data %>% ggplot(aes(x = Wsttime, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Are check-ups a waste of time?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Time Waste"))

# Is the respondent afraid of discovering a disease at a checkup?
barplot2 <-
    data %>% ggplot(aes(x = DiscDisease, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Are you afriad of discovering a\nnew disease?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Discovering Disease"))

# Does the respondent have little faith in the quality of medical service?
barplot3 <-
    data %>% ggplot(aes(x = Lessbelqual, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Do you have little faith in the\nquality of medical service?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Low Faith in Quality"))

# Does the respondent believe check-ups are not urgent or important?
barplot4 <-
    data %>% ggplot(aes(x = NotImp, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Do you believe check-ups are\nnot urgent or important?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Inurgency"))

# Does the respondent believe health is a first priority?
barplot5 <-
    data %>% ggplot(aes(x = HthyPriority, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Do you believe health is a\nfirst priority?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Low priority on health"))

# Do they follow health updates?
barplot6 <-
    data %>% ggplot(aes(x = FlwHealth, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Does you follow health updates?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Updates"))

# Does the respondent have health insurance?
barplot7 <-
    data %>% ggplot(aes(x = HealthIns, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Do you have health insurance?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Insurance"))

# Are check-ups subsidized by the respondent's employer or community?
barplot8 <-
    data %>% ggplot(aes(x = ComSubsidy, y = after_stat(count), 
                        fill = RecPerExam)) +
    geom_bar(position = 'dodge') +
    labs(x="Response",
         y="Frequency",
         title = "Are check-ups subsidized?",
         fill="Months since\nlast check-up", 
         caption = fig_cap("Subsidy"))

grid.arrange(barplot1, barplot2, barplot3, barplot4, barplot5, barplot6, 
             barplot7, barplot8, ncol=2,nrow=4)

rm(barplot1, barplot2, barplot3, barplot4, 
   barplot5, barplot6, barplot7, barplot8)
```

## Impact of Health Status

To investigate the Deputy Assistant Minister's hypothesis, we can make a mosaic plot of the two key variables - `RecPerExam` (how recently the respondent had a regular checkup) and `StabHthStt` (whether the respondent and their family are all in good health.) This type of plot is regularly used to visually inspect whether two categorical variables are independent, and is in that way well suited for this purpose.

```{r}
mosaicplot(table(data$RecPerExam, data$StabHthStt), shade = TRUE, 
           main = "Health Status and Personal Exams Appear Independent", 
           xlab = "Recency of Personal Exam", ylab = "Health Status", 
           sub = fig_cap("Health Status Impact"))
```

From the mosaic plot, it appears that health issues among the respondants and their families are not correlated to the response variable. Each cross-section box is approximately the size you would expect based on only the marginal probabilities, and we can see from the coloring using Standardized Pearson Residuals (or lack thereof, rather) that none of the cross sections are significantly greater or lesser than expected. This implies that Health Status and Personal Exam Recency are likely to be independent variables.

# Methods

Three GLMs are built. One model is a model selected by BIC that tells the health ministry which variables drive what they want. The second model then includes many more variables to control variance so that we can tell the ministry *how much* each covariate influences the result. The third model will be similar to the first in that it contains the same variables selected by BIC, however, the model will also include interactions between all of those variables and `StabHthStt`. Building this model will allow us to test the Deputy Assistant Minister's hypothesis that none of these factors matter much unless you have health issues or know someone in your family with health issues

The response variable for all models is `RecPerExam`. The first model that selects variables using BIC initially considers eighteen variables all discussed in the EDA. The model with lowest BIC value is built as a GLM. The second model uses all of the variables from the first model along with additional variables likely to help control variance based on our EDA. All models will be compared via residual deviance reduction and BIC to determine the best fit for what the Assistant Minister is looking for.

```{r, echo=FALSE}
# Convert yes/no variables to binary
data$StabHthStt <- ifelse(data$StabHthStt=="yes",1,0)
data$Wsttime <- ifelse(data$Wsttime=="yes",1,0)
data$Wstmon <- ifelse(data$Wstmon=="yes",1,0)
data$DiscDisease <- ifelse(data$DiscDisease=="yes",1,0)
data$Lessbelqual <- ifelse(data$Lessbelqual=="yes",1,0)
data$NotImp <- ifelse(data$NotImp=="yes",1,0)
data$HthyPriority <- ifelse(data$HthyPriority=="yes",1,0)
data$ComSubsidy <- ifelse(data$ComSubsidy=="yes",1,0)
data$Habit <- ifelse(data$Habit=="yes",1,0)
data$FlwHealth <- ifelse(data$FlwHealth=="yes",1,0)
```

```{r,echo=FALSE}
# BIC selection
num_pred_variables <- 18
regfit.full <- regsubsets(RecPerExam ~
                            StabHthStt +
                            BMI +
                            Wstmon +
                            Wsttime +
                            DiscDisease +
                            Lessbelqual +
                            NotImp + 
                            HthyPriority +
                            ComSubsidy +
                            Habit + 
                            FlwHealth +
                            AttractInfo +
                            ImpressInfo +
                            SuffInfo +
                            PopularInfo +
                            Assurance +
                            Reliability + 
                            Empathy,
                          data = data,
                          nvmax = num_pred_variables,
                          method = "forward")

reg.summary <- summary(regfit.full)
var_num_bic <- which.min(reg.summary$bic)
plot(reg.summary$bic, xlab = "Number of Variables", ylab = "BIC", type = "l")
points(var_num_bic, reg.summary$bic[var_num_bic], 
       col = "red", cex = 2, pch = 20)
coef(regfit.full, var_num_bic)
```

The best model selected by BIC took the form: $ExamRecency = \beta_{waste\_time}X_1 + \beta_{not\_important}X_2 + \beta_{health\_priority}X_3 + \beta_{subsidy}X_4 + \beta_{habit}X_5$. This means that the variables that the BIC model selection process included were: 

1. Does the respondent believe that checkups are a waste of time?
2. Does the respondent believe that checkups are not urgent or important?
3. Does the respondent believe that health is a first priority?
4. Does the respondent's community or employer subsidize checkups?
5. Does the respondent get the habit of regular checkups from their family or employer?

```{r}
# Final model with BIC
selected_glm <- glm(as.numeric(RecPerExam) ~ Wsttime + NotImp + HthyPriority + 
                        ComSubsidy + Habit,data=data)
selected_summ <- summary(s)
```

```{r}
# variance-controlled model
estimation_glm <- glm(as.numeric(RecPerExam) ~ Wsttime + NotImp + HthyPriority +
                          ComSubsidy + Habit + BMI + Age_gr + Jobstt + 
                          MaritalStt, 
                      data = data)

estimation_summ <- summary(estimation_glm)
```

Fianlly, in order to test the Deputy Assistant Minister's hypothesis, we fit another model that interacted every predictive term with Health Status (and included the main effects) and compared this model against the BIC-selected model based on Deviance reduction This provides a direct comparison of a model that obeys the Deputy Assistant Minister's hypothesis against our baseline model to see if one improves on the other. 

```{r}
interacted <- glm(as.numeric(RecPerExam) ~ Wsttime + NotImp + HthyPriority + 
                      ComSubsidy + Habit + Wsttime:StabHthStt + 
                      NotImp:StabHthStt + HthyPriority:StabHthStt + 
                      ComSubsidy:StabHthStt + Habit:StabHthStt,data=data)
interacted_summ <- summary(interacted)
```

# Results

## Information Ratings

Overall, respondents rate the four types of information (attractiveness, impressiveness, sufficiency, and popularity) with approximately the same distribution (see Figure 1); unimodal, centered at around 3 and slightly right skewed, with slightly more respondents responding with 2/5 then 4/5 and slightly more respondents responding with 1/5 than 5/5. It appears that in general, referencing the tight spread of each individual respondent's rating seen in Figure 2, not only does each type of information have the same marginal distribution, but each individual respondent's ratings are tightly clustered. That is, most respondents gave ratings for the four different information types that are very similar to each other.

## Attribute Ratings

For key metrics of care quality, we can see from Figure 3 that on average patients rate their care reasonably highly. There is clear leftward skew from a high center in each of the plots, and ratings of 1 and 2 are relatively rare. It seems like the performance metrics with the most opportunity for the Ministry to improve are Timeliness and Empathy, since while a reasonable number of patients gave a score of 5/5 for these qualities, these two qualities have the highest density of 1/5 and 2/5 ratings, clearly higher than the other three qualities.

## What drives checkup regularity?

The best model selected by BIC to predict regular checkup attendance retained the following features. 

Variable | Survey Question | Coefficient in Variance-Controlled Model
---------|-----------------|------------
Waste of Time | "Does the respondent believe check-ups are a waste of time?" | @TODO
Not Important | "Does the respondent believe check-ups are not urgent or important?" | @TODO
Health Priority | Does the respondent believe health is a first priority?" | @TODO
Subsidy | "Are check-ups subsidized by the respondent's employer or community?" | @TODO
Habit | "Did the respondent get the habit of regular check-ups from their family or employer?" | @TODO


## The Effect of Stable Health Status

In figure 12 we can see that the distribution of Health Status and Personal Exam Recency appear to closely follow what we would expect just based on the marginal distribution, indicating it is unlikely that these variables are related. To further our argument that Personal Exam Recency does not appear to depend on Health Status, despite the main effect of Health Status being included in the full model tested using BIC, our model selection procedure did not retain the effect, indicating that it had less predictive power than it was worth as an additional variable. However, to be precise, the Deputy Minister's claim was that the *effect of other factors* was dependent on Health Status. To test this hypothesis, we fit another model that interacted every predictive term with Health Status and compared this model against the BIC-selected model by Deviance reduction. The interaction model reduced the residual deviance from $D_{resid, main} = 504.77$ to $D_{resid, interaction} = 502.37$ but used an additional 5 degrees of freedom. This minor improvement is unconvincing that an unstable Health Status is required before an individual's probability of attending a regular checkup can be influenced. This is reflected in comparing the AICs for the two models - the model with only the main effects has an AIC of $2100.777$, while the model with the interaction terms has an AIC of $2106.77$. This indicates that the interaction terms do not provide enough predictive value to pull their weight in the model.

# Conclusions

\newpage

# Appendix

## Residual Plots: BIC Selected Model

## Residual Plots: Estimation Model